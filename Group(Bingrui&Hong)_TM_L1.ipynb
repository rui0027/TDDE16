{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L1: Information retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will apply basic techniques from information retrieval to implement the core of a minimalistic search engine. The data for this lab consists of a collection of app descriptions scraped from the [Google Play Store](https://play.google.com/store/apps?hl=en). From this collection, your search engine should retrieve those apps whose descriptions best match a given query under the vector space model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚ö†Ô∏è Make sure that you have read the [Rules for hand-in assignments](https://www.ida.liu.se/~TDDE16/exam.en.shtml#handins) and the [Policy on cheating and plagiarism](https://www.ida.liu.se/~TDDE16/exam.en.shtml#cheating) before starting with this lab.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The app descriptions come in the form of a compressed [JSON](https://en.wikipedia.org/wiki/JSON) file. Start by loading this file into a [Pandas](https://pandas.pydata.org) [DataFrame](https://pandas.pydata.org/pandas-docs/stable/getting_started/dsintro.html#dataframe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import pandas as pd\n",
    "\n",
    "with bz2.open('app-descriptions.json.bz2') as source:\n",
    "    df = pd.read_json(source)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Pandas, a DataFrame is a table with indexed rows and labelled columns of potentially different types. You can access data in a DataFrame in various ways, including by row and column. To give an example, the code in the next cell shows rows 200‚Äì204:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>Brick Breaker Star: Space King</td>\n",
       "      <td>Introducing the best Brick Breaker game that e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Brick Classic - Brick Game</td>\n",
       "      <td>Classic Brick Game!\\n\\nBrick Classic is a popu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>Bricks Breaker - Glow Balls</td>\n",
       "      <td>Bricks Breaker - Glow Balls is a addictive and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>Bricks Breaker Quest</td>\n",
       "      <td>How to play\\n- The ball flies to wherever you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>Brothers in Arms¬Æ 3</td>\n",
       "      <td>Fight brave soldiers from around the globe on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               name  \\\n",
       "200  Brick Breaker Star: Space King   \n",
       "201      Brick Classic - Brick Game   \n",
       "202     Bricks Breaker - Glow Balls   \n",
       "203            Bricks Breaker Quest   \n",
       "204             Brothers in Arms¬Æ 3   \n",
       "\n",
       "                                           description  \n",
       "200  Introducing the best Brick Breaker game that e...  \n",
       "201  Classic Brick Game!\\n\\nBrick Classic is a popu...  \n",
       "202  Bricks Breaker - Glow Balls is a addictive and...  \n",
       "203  How to play\\n- The ball flies to wherever you ...  \n",
       "204  Fight brave soldiers from around the globe on ...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[200:205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, there are two labelled columns: `name` (the name of the app) and `description` (a textual description). The code in the next cell shows how to access fields from the description column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200    Introducing the best Brick Breaker game that e...\n",
       "201    Classic Brick Game!\\n\\nBrick Classic is a popu...\n",
       "202    Bricks Breaker - Glow Balls is a addictive and...\n",
       "203    How to play\\n- The ball flies to wherever you ...\n",
       "204    Fight brave soldiers from around the globe on ...\n",
       "Name: description, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description'][200:205]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your first task is to implement a preprocessor for your search engine. In the vector space model, *preprocessing* refers to any transformation applied to a text before vectorisation. Here you can restrict yourself to a simple type of preprocessing: tokenisation, stop word removal, and lemmatisation.\n",
    "\n",
    "To implement your preprocessor, you can use [spaCy](https://spacy.io). Make sure to read the [Linguistic annotations](https://spacy.io/usage/spacy-101#annotations) section of the spaCy&nbsp;101; that section contains all the information you need for this problem (and more).\n",
    "\n",
    "Implement your preprocessor by completing the skeleton code in the next cell, adding additional code as you deem necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "def preprocess(text):\n",
    "    # TODO: Replace the next line with your own code.\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    result = []\n",
    "    for token in doc:\n",
    "        if token.is_stop == False and token.is_alpha == True:\n",
    "            result.append(token.lemma_)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your implementation should conform to the following specification:\n",
    "\n",
    "<strong>preprocess</strong> (<em>text</em>)\n",
    "\n",
    "> Preprocesses the given text by tokenising it, removing any stop words, replacing each remaining token with its lemma (base form), and discarding all lemmas that contain non-alphabetical characters. Returns the list of remaining lemmas (represented as strings).\n",
    "\n",
    "To speed up the preprocessing, you should disable loading those spaCy components you do not need, such as the parser, and named entity recogniser. See [here](https://spacy.io/usage/processing-pipelines#disabling) for more information about this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§û Test your code\n",
    "\n",
    "Test your implementation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Apple', 'look', 'buy', 'startup', 'billion']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('Apple is looking at buying U.K. startup for $1 billion')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give the following output:\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['Apple', 'look', 'buy', 'startup', 'billion']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Vectorising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your next task is to vectorise the data ‚Äì and more specifically, to map each app description to a tf‚Äìidf vector. For this you can use the [TfidfVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html) class from [scikit-learn](https://scikit-learn.org/stable/). Make sure to specify your preprocessor from the previous problem as the `tokenizer` &ndash; not the `preprocessor`! &ndash; for the vectoriser. (In scikit-learn terminology, the `preprocessor` handles string-level preprocessing.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# we set the 'tokenizer' param in TfidfVectorizer function as 'preprocess', which is we defined before\n",
    "vectorizer = TfidfVectorizer(tokenizer=preprocess)\n",
    "corpus = df['description'] # row files\n",
    "X = vectorizer.fit_transform(corpus)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§û Test your code\n",
    "\n",
    "Test your implementation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1614, 21396)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should show the dimensions of the matrix `X` to be around 1614 √ó 21389. (The number of rows should be exactly 1614. The number of columns may differ from that given here depending on the version of spaCy and the version of the language model used, as well as the pre-processing.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Retrieving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To complete the search engine, your last task is to write a function that returns the most relevant app descriptions for a given query. An easy way to solve this task is to use scikit-learn&rsquo;s [NearestNeighbors](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.NearestNeighbors.html) class. That class implements unsupervised nearest neighbours learning and allows you to easily find a predefined number of app descriptions whose vector representations are closest to the query vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def search(query):\n",
    "    # TODO: Replace the next line with your own code.\n",
    "    # set training data as X\n",
    "    train_data = X\n",
    "    \n",
    "    # set neigh model and train it based on training data\n",
    "    # return 10 app description based on cosine similarity\n",
    "    neigh = NearestNeighbors(n_neighbors=10, metric='cosine')\n",
    "    neigh.fit(train_data)\n",
    "    \n",
    "    # query to TF-IDF\n",
    "    query_tfidf = vectorizer.transform([query]) # iterable item\n",
    "\n",
    "    # get k-nearst neighbors based on query_tfidf\n",
    "    result = neigh.kneighbors(query_tfidf, return_distance=False)\n",
    "    \n",
    "    # return the result\n",
    "    return df.iloc[result[0],:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your implementation should conform to the following specification:\n",
    "\n",
    "<strong>search</strong> (<em>query</em>)\n",
    "\n",
    "> Returns the 10 app descriptions most similar (in terms of cosine similarity) to the given query as a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§û Test your code\n",
    "\n",
    "Test your implementation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1301</th>\n",
       "      <td>Subway Surfers</td>\n",
       "      <td>DASH as fast as you can! \\nDODGE the oncoming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>Train Conductor World</td>\n",
       "      <td>Master and manage the chaos of international r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1394</th>\n",
       "      <td>Tiny Rails</td>\n",
       "      <td>All aboard for an adventure around the world!\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1300</th>\n",
       "      <td>Subway Princess Runner</td>\n",
       "      <td>Subway princess runner, Bus run, forest rush w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>No Humanity - The Hardest Game</td>\n",
       "      <td>2M+ Downloads All Over The World!\\n\\n* IGN Nom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>Train for Animals - BabyMagica free</td>\n",
       "      <td>üöÇ BabyMagica \"Train for Animals\" is a educatio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>Rush</td>\n",
       "      <td>Are you ready for a thrilling ride?\\n\\nRush th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>LEGO¬Æ DUPLO¬Æ Train</td>\n",
       "      <td>All aboard! Driving the colorful LEGO¬Æ DUPLO¬Æ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1465</th>\n",
       "      <td>Virus War - Space Shooting Game</td>\n",
       "      <td>Warning! Virus invasion! Destroy them with you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>Road Riot</td>\n",
       "      <td>Road Riot is the global sensation that defined...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     name  \\\n",
       "1301                       Subway Surfers   \n",
       "1428                Train Conductor World   \n",
       "1394                           Tiny Rails   \n",
       "1300               Subway Princess Runner   \n",
       "998        No Humanity - The Hardest Game   \n",
       "1429  Train for Animals - BabyMagica free   \n",
       "1168                                 Rush   \n",
       "786                    LEGO¬Æ DUPLO¬Æ Train   \n",
       "1465      Virus War - Space Shooting Game   \n",
       "1153                            Road Riot   \n",
       "\n",
       "                                            description  \n",
       "1301  DASH as fast as you can! \\nDODGE the oncoming ...  \n",
       "1428  Master and manage the chaos of international r...  \n",
       "1394  All aboard for an adventure around the world!\\...  \n",
       "1300  Subway princess runner, Bus run, forest rush w...  \n",
       "998   2M+ Downloads All Over The World!\\n\\n* IGN Nom...  \n",
       "1429  üöÇ BabyMagica \"Train for Animals\" is a educatio...  \n",
       "1168  Are you ready for a thrilling ride?\\n\\nRush th...  \n",
       "786   All aboard! Driving the colorful LEGO¬Æ DUPLO¬Æ ...  \n",
       "1465  Warning! Virus invasion! Destroy them with you...  \n",
       "1153  Road Riot is the global sensation that defined...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search('dodge trains')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The top hit in the list should be *Subway Surfers*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4: Finding terms with low/high idf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the inverse document frequency (idf) of a term is the lower, the more documents from a given collection the term appears in. To get a better understanding for this concept, your next task is to write code to find out which terms from the app descriptions have the lowest/highest idf.\n",
    "\n",
    "Start by sorting the terms in increasing order of idf, breaking ties by falling back on alphabetic order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the next line with your own code.\n",
    "sorted_terms=sorted(zip(vectorizer.get_feature_names_out(),vectorizer.idf_),key=lambda x: (x[1], x[0]))\n",
    "terms = [x[0] for x in sorted_terms]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, print the 10 terms with the lowest/highest idf. How do you explain the results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lowest:\n",
      "['game', 'play', 'feature', 'free', 'new', 'world', 'time', 'app', 'fun', 'use']\n",
      "Highest:\n",
      "['Ô¨Çye', 'Ô¨Årst', 'Ô¨Ånish', 'Ô¨Ånger', 'Ô¨Ånd', 'Ìö®Í≥ºÏùå', 'Ìö®Í≥º', 'ÌöçÎìùÌïú', 'ÌöåÏõêÏùÑ', 'ÌöåÏõêÍ∞ÄÏûÖÏóê']\n"
     ]
    }
   ],
   "source": [
    "# print the 10 terms with lowest idf\n",
    "print('Lowest:')\n",
    "print(terms[:10])\n",
    "\n",
    "# print the 10 terms with highest idf\n",
    "print('Highest:')\n",
    "print(terms[::-1][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The lower idf of a term is, it appears in more documents.\n",
    "\n",
    "The higher idf of a term is, it appears in less documents.\n",
    "\n",
    "1. if we print the 10 terms with the lowest idf, we will get:\n",
    "\n",
    "['game', 'play', 'feature', 'free', 'new', 'world', 'time', 'app', 'fun', 'use']\n",
    "\n",
    "These words are easily associated with games.\n",
    "\n",
    "According to this output, we could say that these 10 terms appear in more documents, more app descriptions used these words.\n",
    "\n",
    "2. when we print 10 terms with the highest idf, we get:\n",
    "\n",
    "['Ô¨Çye', 'Ô¨Årst', 'Ô¨Ånish', 'Ô¨Ånger', 'Ô¨Ånd', 'Ìö®Í≥ºÏùå', 'Ìö®Í≥º', 'ÌöçÎìùÌïú', 'ÌöåÏõêÏùÑ', 'ÌöåÏõêÍ∞ÄÏûÖÏóê']\n",
    "\n",
    "which means only a few app descriptions used these words.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5: Keyword extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often want to extract salient keywords from a document. A simple method is to pick the $k$ terms with the highest tf‚Äìidf value. Your last task in this lab is to implement this method. More specifically, we ask you to implement a function `keywords` that extracts keywords from a text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keywords(text, n=10):\n",
    "    # TODO: Replace the next line with your own code.\n",
    "    sorted_words=sorted(zip(vectorizer.get_feature_names_out(),vectorizer.transform([text]).A[0]),key=lambda x: (x[1], x[0]))[::-1][:n]\n",
    "    keywords=[x[0] for x in sorted_words]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your implementation should conform to the following specification:\n",
    "\n",
    "<strong>keywords</strong> (<em>text</em>, <em>n</em> = 10)\n",
    "\n",
    "> Returns a list with the $n$ (default value: 10) most salient keywords from the specified text, as measured by their tf‚Äìidf value relative to the collection of app descriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ü§û Test your code\n",
    "\n",
    "Test your implementation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train', 'railway', 'railroad', 'rail', 'chaos', 'crash', 'tram', 'timetable', 're', 'railyard']\n"
     ]
    }
   ],
   "source": [
    "print(keywords(df['description'][1428]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should give output similar to the following:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "['train', 'railway', 'railroad', 'rail', 'chaos', 'crash', 'tram', 'timetable', 're', 'overcast']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The exact output may differ slightly depending on the strategy used to break ties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reflection questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following reflection questions will help you prepare for the diagnostic test. Answer each of them in the form of a short text and put your answers in the cell below. You will get feedback on your answers from your lab assistant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RQ 1.1:** Why do we remove common stop words and lemmatise the text? Can you give an example of a scenario where, in addition to common stopwords, there are also *application-specific* stop words?\n",
    "\n",
    "**RQ 1.2:** In Problem&nbsp;2, what do the dimensions of the matrix `X` correspond to? This matrix gives rise to different types of *representations*. Explain what these representations are. What information from the data is preserved, what information is lost in these representations?\n",
    "\n",
    "**RQ 1.3:** What does it mean that a term has a high/low idf value? Based on this, how can we use idf to automatically identify stop words? Why do you think is idf not used as a term weighting on its own, but always in connection with term frequency (tf‚Äìidf)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*TODO: Enter your answers here*\n",
    "\n",
    "**Answer 1.1:**\n",
    "\n",
    "**remove common stop words:**\n",
    "\n",
    "‚ÄùA stop word is a word that is frequent but does not contribute much value for the application in question.‚Äú{Lecture2,Page31}\n",
    "\n",
    "In other words, these words contain less information or lower-level information, remove them will not affect these important information and help us reduce the training time.\n",
    "\n",
    "**lemmatise the text:**\n",
    "\n",
    "Lemmatization is the transformation of the complex morphology of words into their most basic form. Words with the same meaning are unified so as to facilitate subsequent processing and analysis.\n",
    "\n",
    "\"Stop words are application-speciÔ¨Åc ‚Äì there is no single universal list of stop words, and not all applications use such lists.\"{Lecture2,Page31}\n",
    "\n",
    "Stop words are often very common words in a field. We can construct our own list of stop words. Terms are more important in a particular field. For example, in machine learning, the terms \"Markov\", \"supervised\" and \"unsupervised\" are more important and more distinguishable than the terms \"data \", \"accuracy\", \"training\".\n",
    "\n",
    "\n",
    "**Answer 1.2:**\n",
    "\n",
    "The dimension of X is 1614*21396.\n",
    "\n",
    "1614(row) is the number of names; 21396(column), represents the number of significant words in all descriptions.\n",
    "\n",
    "We obtained X by pre-processing, and for records in X, the rows represent the name and the columns represent the processed vocabulary description (represented here by tf-idf). Only words containing important information are kept. The missing information is non-alphabetical characters, e.g. numbers, stop words.\n",
    "\n",
    "\n",
    "**Answer 1.3:**\n",
    "\n",
    "The lower idf of a term is, it appears in more documents.\n",
    "\n",
    "The higher idf of a term is, it appears in less documents.\n",
    "\n",
    "idf reduces the weight of words that appear very frequently in the document set and increases the weight of words that appear very rarely.\n",
    "\n",
    "Instead of evaluating the importance of documents by the vocabulary frequency, the idf value emphasises the specialist vocabulary to better represent the relevance and importance of a document. A high idf means that the more common a word is, the more frequently it appears in documents. A low idf means that a word is less common in the documents.\n",
    "\n",
    "Set a large idf value, if a word has an idf value higher than this it is treated as a stop word.\n",
    "\n",
    "idf overemphasizes the rarity, tf-idf combines come frequency and rarity to avoid reliance on high frequency word weights.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Congratulations on finishing L1! üëç**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
